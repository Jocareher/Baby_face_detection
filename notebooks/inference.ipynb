{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# To avoid ImportError: attempted relative import with no known parent package\n",
    "sys.path.append(\"/Users/jocareher/Library/CloudStorage/OneDrive-Personal/Educación/PhD_UPF_2023/Face_Detection/\")\n",
    "sys.path.append(\"/Users/jocareher/Library/CloudStorage/OneDrive-Personal/Educación/PhD_UPF_2023/Face_Detection/scripts\")\n",
    "\n",
    "from scripts import data_setup, utils, parser, train, engine, visualization\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '../configs/rotated_bbox_config.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    }
   ],
   "source": [
    "# Setting random seed for reproducibility\n",
    "utils.set_seed()\n",
    "\n",
    "# Set the root directory\n",
    "root_dir = \"/Users/jocareher/Downloads/face_dataset/\"\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = [\"3/4_left_sideview\",\"3/4_rigth_sideview\",\"Frontal\",\"Left_sideview\",\"Right_sideview\"]\n",
    "\n",
    "# Register the dataset for training and get datasets sizes\n",
    "train_size, val_size, test_size = data_setup.register_datasets(root_dir=root_dir, class_labels=class_labels)\n",
    "\n",
    "# DATALOADER config\n",
    "train_dataset = \"train\"\n",
    "val_dataset = \"val\"\n",
    "num_workers = 2\n",
    "\n",
    "# Model config\n",
    "base_config_path = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "rotated_bbox_config_path = \"../configs/rotated_bbox_config.yaml\"\n",
    "pretrained_model_url = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "num_classes = len(class_labels)\n",
    "device = \"cpu\"\n",
    "unfreeze_backbone = False\n",
    "freeze_at_block = 0\n",
    "output_dir = \"/Users/jocareher/Downloads/output_fe/\"\n",
    "\n",
    "# Training config\n",
    "ims_per_batch = 2\n",
    "checkpoint_period = 1000\n",
    "base_lr = 0.0025\n",
    "epochs = 100\n",
    "batch_size_per_image = 128\n",
    "warm_steps = 1000\n",
    "gamma = 0.1\n",
    "\n",
    "# Set the model and training configuration\n",
    "model_and_train_config = engine.setup_cfg(\n",
    "    base_config_path=base_config_path,\n",
    "    rotated_bbox_config_path=rotated_bbox_config_path,\n",
    "    pretrained_model_url=pretrained_model_url,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    output_dir=output_dir,\n",
    "    num_classes=num_classes,\n",
    "    num_workers=num_workers,\n",
    "    device=device,\n",
    "    unfreeze_backbone=unfreeze_backbone,\n",
    "    freeze_at_block=freeze_at_block,\n",
    "    ims_per_batch=ims_per_batch,\n",
    "    checkpoint_period=checkpoint_period,\n",
    "    base_lr=base_lr,\n",
    "    epochs=epochs,\n",
    "    train_data_size=train_size,\n",
    "    batch_size_per_image=batch_size_per_image,\n",
    "    warm_steps=warm_steps,\n",
    "    gamma=gamma,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 11:13:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RRPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 105, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): RotatedAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0)\n",
      "        (1): ROIAlignRotated(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0)\n",
      "        (2): ROIAlignRotated(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0)\n",
      "        (3): ROIAlignRotated(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): RotatedFastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=25, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/01 11:13:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5342 images left.\n",
      "\u001b[32m[02/01 11:13:24 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "| 3/4_left_si.. | 563          | 3/4_rigth_s.. | 523          |  Frontal   | 3941         |\n",
      "| Left_sideview | 246          | Right_sidev.. | 288          |            |              |\n",
      "|     total     | 5561         |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/01 11:13:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/01 11:13:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/01 11:13:24 d2.data.common]: \u001b[0mSerializing 5342 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 11:13:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.79 MiB\n",
      "\u001b[32m[02/01 11:13:24 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n"
     ]
    }
   ],
   "source": [
    "trainer = train.FaceTrainer(cfg=model_and_train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the configuration for evaluation\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load the configuration for a pre-trained model\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(\"../configs/rotated_bbox_config.yaml\")\n",
    "\n",
    "# Load the trained model weights\n",
    "cfg.MODEL.WEIGHTS = \"/Users/jocareher/Downloads/model_0004999.pth\"\n",
    "\n",
    "# Set the device to CUDA (GPU support)\n",
    "cfg.MODEL.DEVICE = 'cpu' # cpu\n",
    "\n",
    "# Set the number of classes\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
    "\n",
    "# Set the threshold for object detection\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"val\",)\n",
    "# Initialize the predictor with the configuration\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator = train.FaceTrainer.build_evaluator(cfg, \"val\", output_folder=\"/Users/jocareher/Downloads/\")\n",
    "\n",
    "# Build the validation data loader\n",
    "val_loader = build_detection_test_loader(cfg, \"val\")\n",
    "\n",
    "# Perform evaluation on the validation dataset\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_predictions(\n",
    "    cfg_path=\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    weights_path=\"/Users/jocareher/Downloads/model_final.pth\",\n",
    "    dataset_name=\"val\",\n",
    "    num_classes=5,\n",
    "    score_thresh=0.75,\n",
    "    num_images=12,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "def visualize_all_predictions(\n",
    "    cfg_path: str,\n",
    "    weights_path: str,\n",
    "    dataset_name: str,\n",
    "    num_classes: int,\n",
    "    score_thresh: float,\n",
    "    device: str = \"cpu\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualizes predictions on all images from a specified dataset using a Detectron2 model.\n",
    "\n",
    "    Args:\n",
    "        cfg_path (str): Path to the configuration file for the model.\n",
    "        weights_path (str): Path to the trained model weights.\n",
    "        dataset_name (str): Name of the dataset to visualize (e.g., \"val\", \"test\").\n",
    "        num_classes (int): Number of classes for the model.\n",
    "        score_thresh (float): Score threshold for making predictions.\n",
    "        device (str): Computation device to use ('cpu' or 'cuda').\n",
    "\n",
    "    Displays each image with model predictions including bounding boxes, labels, and confidence scores.\n",
    "    \"\"\"\n",
    "    # Initialize Detectron2 configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(cfg_path))\n",
    "    cfg.merge_from_file(\"../configs/rotated_bbox_config.yaml\")\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    cfg.MODEL.DEVICE = device\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh\n",
    "    cfg.DATASETS.TEST = (dataset_name,)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    # Retrieve dataset dictionaries from the registered dataset\n",
    "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "\n",
    "    # Visualize each image individually\n",
    "    for d in dataset_dicts:\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(img)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        v = Visualizer(\n",
    "            img_rgb,\n",
    "            metadata=MetadataCatalog.get(dataset_name).set(thing_classes=[\n",
    "                \"3/4_left_sideview\", \"3/4_rigth_sideview\", \"Frontal\", \"Left_sideview\", \"Right_sideview\"\n",
    "            ]),\n",
    "            scale=0.5,\n",
    "        )\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter, loss = data_setup.extract_losses(\"/Users/jocareher/Downloads/detectron_pw480719.jreyes.out\")\n",
    "visualization.plot_losses(iter, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all_predictions(\n",
    "    cfg_path=\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    weights_path=\"/Users/jocareher/Downloads/model_final.pth\",\n",
    "    dataset_name=\"val\",\n",
    "    num_classes=5,\n",
    "    score_thresh=0.7,\n",
    "    device='cpu'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
